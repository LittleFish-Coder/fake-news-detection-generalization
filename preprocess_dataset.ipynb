{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 3: Text Classification with plain transformers\n",
    "- ref: https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('dataset/train.csv', sep='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv('dataset/test.csv', sep='\\t', encoding='utf-8')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(train_df.head())\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "print(test_df.head())   # no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "\n",
    "# check NaN values\n",
    "print(f\"Null values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "# print unique labels\n",
    "print(f\"Unique labels in training data:\")\n",
    "print(train_df['label'].unique())\n",
    "# find the row that label == 'label'\n",
    "print(f\"Rows with label 'label':\")\n",
    "print(train_df[train_df['label'] == 'label'])\n",
    "\n",
    "# remove the row that label == 'label'\n",
    "train_df = train_df[train_df['label'] != 'label']\n",
    "\n",
    "# save labels as int type\n",
    "train_df['label'] = train_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "\n",
    "print(train_df.head())\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "At this stage, we transform the text data into embeddings to later feed into the model. \n",
    "\n",
    "We choose the `distilbert-base-uncased` model on Hugging Face for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "train_encodings = tokenizer(train_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "print(train_encodings)\n",
    "print(val_encodings)\n",
    "print(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After tokenization, the texts are converted to input IDs and asampleention masks\n",
    "print(train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we transform the text content into embeddings\n",
    "for embedding in train_encodings['input_ids']:\n",
    "    print(embedding)\n",
    "\n",
    "# we don't need the asampleention mask\n",
    "# for asampleention_mask in train_encodings['asampleention_mask']:\n",
    "#     print(asampleention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out embedding to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_encodings['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding_df = train_df.copy()\n",
    "val_embedding_df = val_df.copy()\n",
    "test_embedding_df = test_df.copy()\n",
    "\n",
    "# rename the column 'text' to 'embeddings'\n",
    "train_embedding_df = train_embedding_df.rename(columns={'text': 'embedding'})\n",
    "val_embedding_df = val_embedding_df.rename(columns={'text': 'embedding'})\n",
    "test_embedding_df = test_embedding_df.rename(columns={'text': 'embedding'})\n",
    "\n",
    "\n",
    "train_embedding_df['embedding'] = train_encodings['input_ids']\n",
    "val_embedding_df['embedding'] = val_encodings['input_ids']\n",
    "test_embedding_df['embedding'] = test_encodings['input_ids']\n",
    "\n",
    "print(train_embedding_df.head())\n",
    "# print(val_embedding_df.head())\n",
    "# print(test_embedding_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframes to csv files\n",
    "train_embedding_df.to_csv('dataset/train_embedding.csv', sep='\\t', index=False)\n",
    "val_embedding_df.to_csv('dataset/val_embedding.csv', sep='\\t', index=False)\n",
    "test_embedding_df.to_csv('dataset/test_embedding.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# read\n",
    "sample = pd.read_csv('dataset/train_embedding.csv', sep='\\t', encoding='utf-8')\n",
    "print(sample.head())\n",
    "\n",
    "print(sample['embedding'][0])   \n",
    "print(type(sample['embedding'][0])) # string\n",
    "\n",
    "# convert the embeddings to list\n",
    "sample['embedding'] = sample['embedding'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# convert the embeddings to list of integers\n",
    "sample['embedding'] = sample['embedding'].apply(lambda x: list(map(int, x)))\n",
    "\n",
    "print(sample['embedding'][0])\n",
    "print(type(sample['embedding'][0])) # list of integers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forgery-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
