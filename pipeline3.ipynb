{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 3: Text Classification with plain transformers\n",
    "- ref: https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_df = pd.read_csv('dataset/train.csv', sep='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv('dataset/test.csv', sep='\\t', encoding='utf-8')\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(train_df.head())\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "print(test_df.head())   # no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "\n",
    "# check NaN values\n",
    "print(train_df.isnull().sum())\n",
    "# print unique labels\n",
    "print(train_df['label'].unique())\n",
    "# find the row that label == 'label'\n",
    "print(train_df[train_df['label'] == 'label'])\n",
    "\n",
    "# remove the row that label == 'label'\n",
    "train_df = train_df[train_df['label'] != 'label']\n",
    "\n",
    "# save labels as int type\n",
    "train_df['label'] = train_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "\n",
    "print(train_df.head())\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "At this stage, we transform the text data into embeddings to later feed into the model. \n",
    "\n",
    "We choose the `distilbert-base-uncased` model on Hugging Face for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "train_encodings = tokenizer(train_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), max_length=512, truncation=True, padding=True)\n",
    "print(train_encodings)\n",
    "print(val_encodings)\n",
    "print(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After tokenization, the texts are converted to input IDs and attention masks\n",
    "print(train_encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we transform the text content into embeddings\n",
    "for embedding in train_encodings['input_ids']:\n",
    "    print(embedding)\n",
    "\n",
    "# we don't need the attention mask\n",
    "# for attention_mask in train_encodings['attention_mask']:\n",
    "#     print(attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize dataset\n",
    "class KDDDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_labels = train_df['label'].tolist()   # pandas series to list\n",
    "val_labels = val_df['label'].tolist()   # pandas series to list\n",
    "\n",
    "train_dataset = KDDDataset(train_encodings, train_labels)\n",
    "val_dataset = KDDDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"Real\", 1: \"Fake\"}\n",
    "label2id = {\"Real\": 0, \"Fake\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 20\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"result_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "test_predictions = classifier(test_df['text'].tolist())\n",
    "\n",
    "print(test_predictions)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Text: {test_df.iloc[i]['text']}\")\n",
    "    print(f\"Prediction: {test_predictions[i]['label']}\")\n",
    "    print(f\"Confidence: {test_predictions[i]['score']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forgery-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
